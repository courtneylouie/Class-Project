{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**  \n",
    "In this notebook, I use the scholarly package to get publication titles and years from Google Scholar, for animal science professors at 5 universities in the US.\n",
    "\n",
    "**The schools**  \n",
    "In addition to UC Davis, I chose four universities geographically spread across the US. I chose Cornell University in New York, Texas A&M University, Ohio State University, and University of Florida. As abbreviations and variable names throughout this project, UC Davis will be \"Davis\", Cornell University will be \"Cornell\", Texas A&M will be \"TAMU\", Ohio State will be \"Ohio\", and University of Florida will be \"Florida\".\n",
    "\n",
    "**The professors**  \n",
    "I took all current (not Emiriti) professors from the animal science departments at these universities. UC Davis had 44, Cornell had 16, Texas A&M had 52, Ohio State had 33, and Florida State had 38. In total, there were 183. \n",
    "\n",
    "**The scholarly package**  \n",
    "I used the scholarly.search_author() function to search by author. Given the name of any author, it checks for the person's author profile and if it exists, the function returns an object containing information about all the publications linked to that profile. Pros and cons of this package are discussed at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scholarly\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import requests_cache\n",
    "requests_cache.install_cache(\"mycache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "davis_profs = [\"Trish Berger\", \"Richard A. Blatchford\", \"David Bunn\", \"Hao Cheng\",\n",
    "               \"Fred S. Conte\", \"Anna C. Denicol\", \"Mary E. Delany\", \"Edward J. DePeters\",\n",
    "               \"John Eadie\", \"James Fadel\", \"Jackson Gross\", \"Matthias Hess\", \n",
    "               \"Kristina Horback\", \"Russ Hovey\", \"Josh Hull\", \"Silas Hung\", \n",
    "               \"Ermias Kebreab\", \"Annie J. King\", \"Kirk Klasing\", \"Dietmar Kueltz\",  \n",
    "               \"Yanhong Liu\", \"Elizabeth A. Maga\", \"Maja M. Makagon\", \"Bernie May\", \n",
    "               \"Juan F. Medrano\", \"Deanne Meyer\", \"Michael J. Mienaltowski\", \n",
    "               \"Michael R. Miller\", \"Frank Mitloehner\", \"James D. Murray\", \n",
    "               \"Anita M. Oberbauer\",  \"James W. Oltjen\", \"Lee Allen Pettey\", \n",
    "               \"Peter H. Robinson\", \"Pablo J. Ross\", \"Roberto D. Sainz\", \"Andrea Schreier\", \n",
    "               \"Anne E. Todgham\", \"Cassandra B. Tucker\", \"Alison Van Eenennaam\", \n",
    "               \"Jason V. Watters\", \"Crystal Yang\", \"Huaijun Zhou\", \"Richard A. Zinn\"]\n",
    "\n",
    "cornell_profs = [\"Yves Boisclair\", \"Dan Brown\", \"Walter Butler\", \"Debbie Cherney\", \n",
    "                \"Jerrie Gavalchin\", \"Julio Giordano\", \"Heather Huson\", \n",
    "                \"Patricia Johnson\", \"Quirine Ketterings\", \"Xin Gen Lei\", \n",
    "                \"Joseph McFadden\", \"Thomas Overton\", \"Susan Quirk\", \"Vimal Selvaraj\",\n",
    "                \"Michael Thonney\", \"Michael Van Amburgh\"]\n",
    "\n",
    "tamu_profs = [\"Ashley Arnold\", \"Jason Banta\", \"Fuller Bazer\", \"Rodolfo Cardoso\",\n",
    "             \"Bruce Carpenter\", \"Gordon Carstens\", \"Alejandro Castillo\", \"Jason Cleere\",\n",
    "             \"Reinaldo Cooke\", \"H Russell Cross\", \"Courtney Daigle\", \"Kathrin Dunlap\", \n",
    "             \"Davis Forrest\", \"Kerri Gehring\", \"Clare Gill\", \"Jason Gill\", \"Ron Gill\", \n",
    "             \"Davey Griffin\", \"Thomas Hairgrove\", \"Dan Hale\", \"Steve Hammack\", \"Andy Herring\",\n",
    "             \"Nancy Ing\", \"Jenny Jennings\", \"Ellen Jordan\", \"Chris Kerth\", \"G Cliff Lamb\", \n",
    "             \"Jessica Leatherwood\", \"Charles Long\", \"Ted McCollum\", \"Rhonda Miller\",\n",
    "             \"Wes Osburn\", \"Joe Paschal\", \"Shawn Ramsey\", \"Ron Randel\", \"Reid Redden\", \n",
    "             \"Penny Riggs\", \"David Riley\", \"Jim Sanders\", \"Carey Satterfield\", \"Jeff Savell\",\n",
    "             \"Chris Skaggs\", \"Stephen B. Smith\", \"Matthew Taylor\", \"Luis Tedeschi\", \n",
    "             \"Daniel Waldron\", \"Thomas H Welsh\", \"Sarah White\", \"Travis Whitney\", \n",
    "             \"Tryon Wickersham\", \"Gary Williams\", \"Guoyao Wu\"]\n",
    "\n",
    "ohio_profs = [\"Lisa Bielke\", \"Stephen Boyles\", \"Daniel Clark\", \"Kimberly Cole\", \n",
    "             \"Michael Cressman\", \"Michael Davis\", \"Maurice Eastridge\", \"Thaddeus Ezeji\",\n",
    "             \"Jeffrey Firkins\", \"John Foltz\", \"Lyda Garcia\", \"Alvaro Garcia Guerra\",\n",
    "             \"Kelly George\", \"Sheila Jacobi\", \"Justin Kieffer\", \"Chanhee Lee\", \"Kichoon Lee\",\n",
    "             \"Michael Lilburn\", \"Pasha Lyvers Peffer\", \"Steven Moeller\", \"Luis Moraes\", \n",
    "             \"Herbert Ockerman\", \"Joseph Ottobre\", \"Monique Pairis-Garcia\", \"Elizabeth Parker\", \n",
    "             \"Tony Parker\", \"William Pope\", \"Alejandro Relling\", \"Ramesh Selvaraj\",\n",
    "             \"Sandra Velleman\", \"William Weiss\", \"Macdonald Wick\", \"Zhongtang Yu\"]\n",
    "\n",
    "florida_profs = [\"Adegbola Adesogan\", \"John Arthington\", \"Mario Binelli\", \"Jeremy Block\", \n",
    "                \"John Bromfield\", \"Samantha A. Brooks\", \"Ilaria Capua\", \"Chad Carr\", \n",
    "                \"Geoff Dahl\", \"Albert De Vries\", \"Nicholas DiLorenzo\", \"John P. Driver\", \n",
    "                \"Mauricio Elzo\", \"Antonio Faciola\", \"Luiz Ferraretto\", \"Timothy J. Hackmann\",\n",
    "                \"Peter Hansen\", \"H. Arie Havelaar\", \"Matthew Hersom\", \"Kwang Cheol Jeong\",\n",
    "                \"Jimena Laporta\", \"Raluca Mateescu\", \"Joel McQuagge\", \"Emily K. Miller-Cushon\",\n",
    "                \"Philipe Moriel\", \"Corwin D. Nelson\", \"Pascal Oltenacu\", \n",
    "                \"Francisco Penagaricano\", \"Jose Eduardo Santos\", \"Jason M. Scheffler\",\n",
    "                \"Tracy L. Scheffler\", \"Charlie Staples\", \"Saundra TenBroeck\", \"Todd Thrift\", \n",
    "                \"Lori Warren\", \"Carissa Wickens\", \"Sally Williams\", \"Stephanie Wohlgemuth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44 professors from Davis\n",
      "There are 16 professors from Cornell\n",
      "There are 52 professors from Texas A&M\n",
      "There are 33 professors from Ohio State\n",
      "There are 38 professors from University of Florida\n",
      "The total is 183\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(davis_profs), \"professors from Davis\")\n",
    "print(\"There are\", len(cornell_profs), \"professors from Cornell\")\n",
    "print(\"There are\", len(tamu_profs), \"professors from Texas A&M\")\n",
    "print(\"There are\", len(ohio_profs), \"professors from Ohio State\")\n",
    "print(\"There are\", len(florida_profs), \"professors from University of Florida\")\n",
    "\n",
    "print(\"The total is\", len(davis_profs) + len(cornell_profs) + \\\n",
    "      len(tamu_profs) + len(ohio_profs) + len(florida_profs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pubs(name, school):\n",
    "    \"\"\"Extract from Google Scholar all publications \n",
    "    (including title, year of publications, and number of citations) \n",
    "    for a given professor at a given university\"\"\"\n",
    "    search_query = scholarly.search_author(name + \" \" + school)\n",
    "    try:\n",
    "        author = next(search_query).fill()\n",
    "        listt = []\n",
    "        listc = []\n",
    "        listy = []\n",
    "                        \n",
    "        for i in range(len(author.publications)):\n",
    "            listt.append(author.publications[i].bib['title'])\n",
    "            \n",
    "            try: \n",
    "                listy.append(author.publications[i].bib['year'])\n",
    "            except:\n",
    "                listy.append(0)\n",
    "                \n",
    "            try: \n",
    "                listc.append(author.publications[i].citedby)\n",
    "            except:\n",
    "                listc.append(0)    \n",
    "                \n",
    "        df = pd.DataFrame({\"title\": listt, \"year\":listy, \"citedby\": listc})\n",
    "        df.insert(0, \"school\", school)\n",
    "        df.insert(1, \"name\", name.split(\" \")[-1])\n",
    "        \n",
    "    except:\n",
    "        print(\"No profile for\", name)\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "    return df;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Details about this function**  \n",
    "I found (through trial-and-error) that the best search term uses the professor's full name, including middle initial if available, and included the university name. By doing this, I was able to get the correct profile most of the time. In the next notebook (data_exploration.ipynb), I went through the observations and found that using this method, only 2 wrong profiles were found. The function doesn't work when the person doesn't have a profile set up, so out of the 183 professors, I was only able to get data on 58 of them, with about 9000 publications. After removing the two wrong ones, I was left with 56 professors and about 8000 publications.\n",
    "\n",
    "The outer try/except is to catch professors who don't have profiles. The inner try/excepts are to catch instances where the year or number of citations ('citedby') were not available. When the year wasn't available though, it was usually an issue with reading in the Google Scholar data, rather than a legitimate publication, so in the next notebook, I removed all observations with a year of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_school(profs_list, school):\n",
    "    \"\"\"Proccesses all the professors for a given school\"\"\"\n",
    "    global schooldf\n",
    "    for x in profs_list:\n",
    "        df = get_pubs(x, school)\n",
    "        schooldf = schooldf.append(df)\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The next two cells take a few hours to run due to built-in sleeps.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the first item to initialize the data frame\n",
    "schooldf = get_pubs(\"Trish Berger\", \"Davis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_school(davis_profs[1:], \"Davis\") # Skip the first one to avoid duplicates\n",
    "get_school(cornell_profs, \"Cornell\")\n",
    "get_school(tamu_profs, \"TAMU\")\n",
    "get_school(ohio_profs, \"Ohio\")\n",
    "get_school(florida_profs, \"Florida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting all the data, I will export it to a text file and use that going forward. I don't want to repeatedly rerun this code because:\n",
    "- it takes hours to run due to built-in sleeps\n",
    "- it's courteous to avoid making so many redundant requests\n",
    "- scholarly is a web scraper, so it's good to have a local copy of my data in case Google Scholar makes changes in ways that make scholarly not work anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schooldf.to_csv(\"data.txt\", sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros and Cons of the scholarly package**  \n",
    "The major problem with this package is that it requires that the person's Google Scholar profile is set up. A Google Scholar profile is basically a collection of all papers authored by a specific person, and the person needs to log onto Google Scholar and verify using the email address from their university. Of the 183 professors, 56 of them had profiles set up (14 at UCD, 2 at Cornell, 14 at Texas A&M, 7 at Ohio State, 22 at Florida State).\n",
    "\n",
    "The second major problem with scholarly is that it is a web scraper and doesn't use an official API. This means that this package may stop working if there are any changes in the Google Scholar site or results pages. For this reason, I exported and saved my data.\n",
    "\n",
    "When the profile is set up, the quality of data is excellent. Because of the nature of the Google Scholar profile, once the correct profile is identified, every paper associated with that profile is authored by the correct person. This is helpful because it allows me to assess wrongness at the professor level (around 50 checks), whereas a traditional Google search would require checking each paper for the author (around 9000 checks).\n",
    "\n",
    "Additionally, every paper authored by that person is returned. This means that the number of publications returned is meaningful. In contrast, a traditional Google search may return thousands of results, and I would simply cut if off after a certain number, making the number of publications arbitrary.\n",
    "\n",
    "There were a few issues reading in some of the publication titles, usually towards the end of the results for a professor. In these cases, I noticed it was common that a year was not available, so I set those years equal to 0. Then in the next notebook, I remove any observations with a year of 0. This was a fairly effective way to remove most mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why I chose to stick with scholarly**  \n",
    "I ultimately chose not to use another method to obtain data for professors who did not have Google Scholar profiles set up. The main reason is because the amount of data that I was able to get using scholarly was adequate (56 professors, 8000 observations). The second reason is that data quality would be much lower. For example, if I were to search \"Dan Brown Cornell\" in Google Scholar, I might end up with a paper about brown rice, authored by someone at Cornell whose first name was Dan and whose last name was something else. Also, the number of publications per professor would be arbitrary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
