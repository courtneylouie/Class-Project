{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**  \n",
    "In this notebook, I use the scholarly package to get publication titles and years from Google Scholar, for animal science professors at 5 universities in the US.\n",
    "\n",
    "**The schools**  \n",
    "In addition to UC Davis, I chose four universities geographically spread across the US. I chose Cornell University in New York, Texas A&M University, Ohio State University, and Florida State University. As abbreviations and variable names throughout this project, UC Davis will be \"Davis\", Cornell Univerity will be \"Cornell\", Texas A&M will be \"TAMU\", Ohio State will be \"Ohio\", and Florida State will be \"Florida\".\n",
    "\n",
    "**The professors**  \n",
    "I took all current (not Emiriti) professors from the animal science departments at these universities. UC Davis had 44, Cornell had 16, Texas A&M had 52, Ohio State had 33, and Florida State had 38. In total, there were 183. \n",
    "\n",
    "**The scholarly package**  \n",
    "I used the scholarly.search_author() function to search by author. Given the name of any author, it checks for the person's author profile and if it exists, the function returns an object containing information about all the publications linked to that profile. Pros and cons of this package are discussed at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scholarly\n",
    "import pandas as pd\n",
    "\n",
    "def get_pubs(name, school):\n",
    "    \"\"\"Extract from Google Scholar all publications for a given person\"\"\"\n",
    "    search_query = scholarly.search_author(name + \" \" + school)\n",
    "    try:\n",
    "        author = next(search_query).fill()\n",
    "        listt = [author.publications[0].bib['title'],author.publications[1].bib['title']]\n",
    "        try:\n",
    "            listy = [author.publications[0].bib['year'],author.publications[1].bib['year']]\n",
    "        except:\n",
    "            listy = [0,0]\n",
    "        for i in range(len(author.publications)):\n",
    "            listt.append(author.publications[i].bib['title'])\n",
    "            try: \n",
    "                listy.append(author.publications[i].bib['year'])\n",
    "            except:\n",
    "                listy.append(0)\n",
    "        df = pd.DataFrame({\"title\": listt[2:], \"year\":listy[2:]})\n",
    "        df.insert(0, \"school\", school)\n",
    "        df.insert(1, \"name\", name.split[-1])\n",
    "    except:\n",
    "        print(\"No profile for\", name)\n",
    "        df = pd.DataFrame()\n",
    "    return df;   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "davis_profs = [\"Trish Berger\", \"Richard A. Blatchford\", \"David Bunn\", \"Hao Cheng\",\n",
    "               \"Fred S. Conte\", \"Anna C. Denicol\", \"Mary E. Delany\", \"Edward J. DePeters\",\n",
    "               \"John Eadie\", \"James Fadel\", \"Jackson Gross\", \"Matthias Hess\", \n",
    "               \"Kristina Horback\", \"Russ Hovey\", \"Josh Hull\", \"Silas Hung\", \n",
    "               \"Ermias Kebreab\", \"Annie J. King\", \"Kirk Klasing\", \"Dietmar Kueltz\",  \n",
    "               \"Yanhong Liu\", \"Elizabeth A. Maga\", \"Maja M. Makagon\", \"Bernie May\", \n",
    "               \"Juan F. Medrano\", \"Deanne Meyer\", \"Michael J. Mienaltowski\", \n",
    "               \"Michael R. Miller\", \"Frank Mitloehner\", \"James D. Murray\", \n",
    "               \"Anita M. Oberbauer\",  \"James W. Oltjen\", \"Lee Allen Pettey\", \n",
    "               \"Peter H. Robinson\", \"Pablo J. Ross\", \"Roberto D. Sainz\", \"Andrea Schreier\", \n",
    "               \"Anne E. Todgham\", \"Cassandra B. Tucker\", \"Alison Van Eenennaam\", \n",
    "               \"Jason V. Watters\", \"Crystal Yang\", \"Huaijun Zhou\", \"Richard A. Zinn\"]\n",
    "\n",
    "cornell_profs = [\"Yves Boisclair\", \"Dan Brown\", \"Walter Butler\", \"Debbie Cherney\", \n",
    "                \"Jerrie Gavalchin\", \"Julio Giordano\", \"Heather Huson\", \n",
    "                \"Patricia Johnson\", \"Quirine Ketterings\", \"Xin Gen Lei\", \n",
    "                \"Joseph McFadden\", \"Thomas Overton\", \"Susan Quirk\", \"Vimal Selvaraj\",\n",
    "                \"Michael Thonney\", \"Michael Van Amburgh\"]\n",
    "\n",
    "tamu_profs = [\"Ashley Arnold\", \"Jason Banta\", \"Fuller Bazer\", \"Rodolfo Cardoso\",\n",
    "             \"Bruce Carpenter\", \"Gordon Carstens\", \"Alejandro Castillo\", \"Jason Cleere\",\n",
    "             \"Reinaldo Cooke\", \"H Russell Cross\", \"Courtney Daigle\", \"Kathrin Dunlap\", \n",
    "             \"Davis Forrest\", \"Kerri Gehring\", \"Clare Gill\", \"Jason Gill\", \"Ron Gill\", \n",
    "             \"Davey Griffin\", \"Thomas Hairgrove\", \"Dan Hale\", \"Steve Hammack\", \"Andy Herring\",\n",
    "             \"Nancy Ing\", \"Jenny Jennings\", \"Ellen Jordan\", \"Chris Kerth\", \"G Cliff Lamb\", \n",
    "             \"Jessica Leatherwood\", \"Charles Long\", \"Ted McCollum\", \"Rhonda Miller\",\n",
    "             \"Wes Osburn\", \"Joe Paschal\", \"Shawn Ramsey\", \"Ron Randel\", \"Reid Redden\", \n",
    "             \"Penny Riggs\", \"David Riley\", \"Jim Sanders\", \"Carey Satterfield\", \"Jeff Savell\",\n",
    "             \"Chris Skaggs\", \"Stephen B. Smith\", \"Matthew Taylor\", \"Luis Tedeschi\", \n",
    "             \"Daniel Waldron\", \"Thomas H Welsh\", \"Sarah White\", \"Travis Whitney\", \n",
    "             \"Tryon Wickersham\", \"Gary Williams\", \"Guoyao Wu\"]\n",
    "\n",
    "ohio_profs = [\"Lisa Bielke\", \"Stephen Boyles\", \"Daniel Clark\", \"Kimberly Cole\", \n",
    "             \"Michael Cressman\", \"Michael Davis\", \"Maurice Eastridge\", \"Thaddeus Ezeji\",\n",
    "             \"Jeffrey Firkins\", \"John Foltz\", \"Lyda Garcia\", \"Alvaro Garcia Guerra\",\n",
    "             \"Kelly George\", \"Sheila Jacobi\", \"Justin Kieffer\", \"Chanhee Lee\", \"Kichoon Lee\",\n",
    "             \"Michael Lilburn\", \"Pasha Lyvers Peffer\", \"Steven Moeller\", \"Luis Moraes\", \n",
    "             \"Herbert Ockerman\", \"Joseph Ottobre\", \"Monique Pairis-Garcia\", \"Elizabeth Parker\", \n",
    "             \"Tony Parker\", \"William Pope\", \"Alejandro Relling\", \"Ramesh Selvaraj\",\n",
    "             \"Sandra Velleman\", \"William Weiss\", \"Macdonald Wick\", \"Zhongtang Yu\"]\n",
    "\n",
    "florida_profs = [\"Adegbola Adesogan\", \"John Arthington\", \"Mario Binelli\", \"Jeremy Block\", \n",
    "                \"John Bromfield\", \"Samantha A. Brooks\", \"Ilaria Capua\", \"Chad Carr\", \n",
    "                \"Geoff Dahl\", \"Albert De Vries\", \"Nicholas DiLorenzo\", \"John P. Driver\", \n",
    "                \"Mauricio Elzo\", \"Antonio Faciola\", \"Luiz Ferraretto\", \"Timothy J. Hackmann\",\n",
    "                \"Peter Hansen\", \"H. Arie Havelaar\", \"Matthew Hersom\", \"Kwang Cheol Jeong\",\n",
    "                \"Jimena Laporta\", \"Raluca Mateescu\", \"Joel McQuagge\", \"Emily K. Miller-Cushon\",\n",
    "                \"Philipe Moriel\", \"Corwin D. Nelson\", \"Pascal Oltenacu\", \n",
    "                \"Francisco Penagaricano\", \"Jose Eduardo Santos\", \"Jason M. Scheffler\",\n",
    "                \"Tracy L. Scheffler\", \"Charlie Staples\", \"Saundra TenBroeck\", \"Todd Thrift\", \n",
    "                \"Lori Warren\", \"Carissa Wickens\", \"Sally Williams\", \"Stephanie Wohlgemuth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44 professors from Davis\n",
      "There are 16 professors from Cornell\n",
      "There are 52 professors from Texas A&M\n",
      "There are 33 professors from Ohio State\n",
      "There are 38 professors from Florida State\n",
      "The total is 183\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(davis_profs), \"professors from Davis\")\n",
    "print(\"There are\", len(cornell_profs), \"professors from Cornell\")\n",
    "print(\"There are\", len(tamu_profs), \"professors from Texas A&M\")\n",
    "print(\"There are\", len(ohio_profs), \"professors from Ohio State\")\n",
    "print(\"There are\", len(florida_profs), \"professors from Florida State\")\n",
    "\n",
    "print(\"The total is\", len(davis_profs) + len(cornell_profs) + len(tamu_profs) + len(ohio_profs) + len(florida_profs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_school(profs_list, school):\n",
    "    \"\"\"Proccesses all the professors for a given school\"\"\"\n",
    "    global schooldf\n",
    "    for x in profs_list:\n",
    "        df = get_pubs(x, school)\n",
    "        schooldf = schooldf.append(df)\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the first item to initialize the data frame\n",
    "schooldf = get_pubs(\"Trish Berger\", \"Davis\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_school(davis_profs[1:], \"Davis\") # Skip the first one to avoid duplicates\n",
    "get_school(cornell_profs, \"Cornell\")\n",
    "get_school(tamu_profs, \"TAMU\")\n",
    "get_school(ohio_profs, \"Ohio\")\n",
    "get_school(flordia_profs, \"Florida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting all the data, I will export it to a text file so that I don't need to rerun this code every time. This is because a) it takes forever to run due to built-in sleeps, b) it's rude to make so many redundant requests and c) it's good to have a local copy of my data in case Google Scholar makes changes in ways that make my script or scholarly not work anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data in case Google scholar makes changes that break the package I'm using\n",
    "schooldf.to_csv(\"data.txt\", sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros and Cons of the scholarly package**  \n",
    "The major problem with this package is that it requires that the person's Google Scholar profile is set up. A Google Scholar profile is basically a collection of all papers authored by a specific person, and the person needs to log onto Google Scholar and verify using the email address from their university. Of the 183 professors, 56 of them had profiles set up (14 at UCD, 2 at Cornell, 14 at Texas A&M, 7 at Ohio State, 22 at Florida State).\n",
    "\n",
    "The second major problem with scholarly is that it is a web scraper and doesn't use an official API. This means that this package may stop working if there are any change in the Google Scholar site or results pages. For this reason, I exported and saved my data.\n",
    "\n",
    "For the search term, I used the professor's full name, including middle initial if available, and included the university name. By doing this, I was able to get the correct profile most of the time (only two were wrong). I went through the results by hand, and since I have some experience in the animal science field, it was easy for me to tell when the wrong profile was identified.\n",
    "\n",
    "When the profile is set up, the quality of data is excellent. Because of the nature of the Google Scholar profile, once the correct profile is identified, every paper associated with that profile is authored by the correct person. This is helpful because it allows me to assess wrongness at the professor level (around 50 checks), whereas a traditional Google search would require checking each paper for the author (around 9000 checks).\n",
    "\n",
    "Additionally, every paper authored by that person is returned. This means that the number of publications returned is meaningful. In contrast, a traditional Google search may return thousands of results, and I would simply cut if off after a certain number, making the number of publications arbitrary.\n",
    "\n",
    "There were a few issues reading in some of the publication titles, usually towards the end of the results for a professor. In these cases, I noticed it was common that a year was not available, so I set those years equal to 0. Then in the next notebook, I remove any observations with a year of 0. This was a fairly effective way to remove most mistakes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
